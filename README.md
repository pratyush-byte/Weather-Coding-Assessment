# Weather Coding Challenge â€“ QuickÂ Guide

## Table of Contents

1. [Set-up]
2. [Project Structure]
3. [Problem 1 â€“ Schema]
4. [Problem 2 â€“ Ingestion]
5. [Problem 3 â€“ Data Analysis]
6. [Problem 4 â€“ REST API]
7. [Automated Tests]
8. [Deployment]
9. [Verify Everything]
10. [Extra Credit: Deployment Architecture]

---

## ðŸ› Â 1Â Â·Â Setâ€‘up (oneâ€‘time)

1. **Create & activate** a virtualâ€‘environment  
   ```bash
   python3 -m venv venv && source venv/bin/activate  # Windows: venv\Scripts\activate
   ```
2. **Install libraries** (all problems)  
   ```bash
   python Initial_checks_install.py
   ```

---

##  Project Structure

```
weather-coding-assessment/
â”œâ”€â”€ api/              # API logic (routes, models, helpers)
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ routes.py
â”‚   â”œâ”€â”€ pagination.py
â”œâ”€â”€ tests/            # All automated tests
â”œâ”€â”€ logs/             # Log files
â”œâ”€â”€ app_flask.py      # API entry point
â”œâ”€â”€ ingest.py         # Data ingestion script
â”œâ”€â”€ Data_analysis.py  # Data analysis script
â”œâ”€â”€ create_db.py      # DB schema creation
â”œâ”€â”€ requirements.txt  # Python dependencies
â”œâ”€â”€ Dockerfile        # For containerized deployment
â””â”€â”€ README.md         # This file
```
### Docker (Planned for Deployment)

> **Note:**  
> Docker support is planned, but a `Dockerfile` is not yet included in this repository.  
> When available, you will be able to build and run the API in a container for easy deployment.
---

## My solution and approach including with step by step instructions to run the code

---

## ProblemÂ 1Â â€“ Schema

3. **Create the empty tables**  
   *Due to storage issue in GIT I have deleted the weather.db file, so please run this file:*
   ```bash
   python create_db.py       # produces weather.db with 3 empty tables
   ```                   

| Table                  | What it stores                   PrimaryÂ Key           |
| ---------------------- | -------------------------------- --------------------  |
| `station`              | Every weatherâ€‘station ID         |`id`                 |
| `weather_daily`        | *stationÂ Ã—Â day* raw observations | `(station_id, date` |
| `weather_yearly_stats` | *stationÂ Ã—Â year* aggregates      | `(station_id, year)`|

*Integers keep raw units:â€¯tenthâ€‘Â°C & tenthâ€‘mm; `â€‘9999` â†’Â `NULL`.*

---

## ProblemÂ 2Â â€“ Ingestion

### âœ±â€¯Significance

Turn thousands of flatâ€‘files into relational rows **safely** (no duplicates) and **quickly** (bulk inserts, batching).

### Â Key Features

| Aspect                | Detail                                                                  |
| --------------------- | ----------------------------------------------------------------------- |
| **Script**            | `ingest.py`                                                             |
| **Idempotent**        | `ON CONFLICT DO NOTHING` (composite PK) â€” reruns never duplicate rows.  |
| **Duplicate Metrics** | Every batch logs *new* vs. *dup*; perâ€‘file totals in `logs/ingest.log`. |
| **Batching**          | SQLite â‰¤â€¯180 rows/flush (under 999â€‘param limit).                        |
| **Logging**           | Console **and** file `logs/ingest.log`.                                 |

### â–¶ï¸ŽÂ Run

```bash
python ingest.py      
```

Sample output

```
USC00110072 â€¦  10â€¯957 new Â· 0 dup
USC00110073 â€¦       0 new Â· 10â€¯957 dup
Done: 10â€¯957â€¯890 new Â· 10â€¯957 dup
```

---

## ProblemÂ 3Â â€“ DataÂ Analysis

### âœ±â€¯Significance

Condense millions of daily rows into **one row per stationâ€¯Ã—â€¯year**, ready for fast API queries.  A diff log detects data drift instantly.

### Â KeyÂ Features

| Aspect          | Detail                                                 |
| --------------- | ------------------------------------------------------ |
| **Script**      | `Data_analysis.py`                                 |
| **Model**       | Table `weather_yearly_stats` (PK `(station_id, year)`) |
| **SQLiteâ€‘only** | One aggregate `GROUPÂ BY` query â€” no temp tables.       |
| **Idempotent**  | Table is rebuilt every run.                            |
| **DiffÂ Log**    | NEW / CHG rows written to `logs/data_analysis.log`.    |

### â–¶ï¸ŽÂ Run

```bash
python Data_analysis.py
```

Example tail of log

```
NEW   USC00110072 1985  Tmax=12.3  Tmin=-1.5  Precip=67.4
â–² Yearly aggregation finished: 4â€¯820 added Â· 0 changed Â· 0 removed Â· 0 unchanged (4.5Â s)
```

---

## ProblemÂ 4Â â€“ RESTÂ API

### âœ±â€¯Significance

Serve cleaned weather data to any client via JSON with **filtering, pagination & live docs**.

### Â KeyÂ Features

| Aspect             | Detail                                                                      |
| ------------------ | --------------------------------------------------------------------------- |
| **App**            | `app_flask.py` (FlaskÂ +Â Flaskâ€‘RESTX)                                        |
| **Endpoints**      | `/api/weather` Â· `/api/weather/stats`                                       |
| **Filters**        | `station_id`, `date` (range) on daily; `station_id`, `year` on yearly stats |
| **Pagination**     | `page` & `page_size` query params; 404 if pageâ€‘outâ€‘ofâ€‘range                 |
| **Docs (Swagger)** | OpenAPI UI at `/docs` (autoâ€‘generated)                                      |

### â–¶ï¸ŽÂ Run

```bash
export FLASK_APP=app_flask.py     # Windows: set FLASK_APP=app_flask.py
flask run                          # starts http://127.0.0.1:5000/
# OR RUN
python app_flask.py
```

*Open* [http://127.0.0.1:5000/docs](http://127.0.0.1:5000/docs) for Swagger, or test with Postman:

```
GET http://127.0.0.1:5000/api/weather?page=1&page_size=5&station_id=USC00110072
```

---

##  Automated Tests

All modules are covered by automated tests using `pytest`.

### â–¶ï¸ŽÂ Run All Tests

Install pytest if you haven't:

```bash
pip install pytest
```

Run all tests:

```bash
pytest -q
```

---

##  Deployment

### Local Development

1. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
2. Run the API:
   ```bash
   python app_flask.py
   ```

### Docker (Recommended for Deployment)

1. Build the Docker image:
   ```bash
   docker build -t weather-api .
   ```
2. Run the container:
   ```bash
   docker run -p 5000:5000 weather-api
   ```

### Cloud (Example: AWS Elastic Beanstalk)

- Use the provided Dockerfile.
- Set environment variables for DB connection if needed.
- Use AWS RDS for production database.

---

## ðŸ”ŽÂ Verify Everything

```bash
python check_counts.py            # rows & samples from all three tables
pytest -q                         # runs unit tests (all modules)
```

---

## EXTRA CREDIT â€“ Deployment Architecture

I donâ€™t have hands-on production cloud experience yet, but from my studies and research this is the approach I would take. Iâ€™d first containerize the whole project with Docker, ensuring the code and dependencies run identically everywhere. Iâ€™d push that image to AWS Elastic Beanstalk, which can launch and manage an EC2 instance, pull the image, and keep the Flask API live behind an autoscaling load balancer. For storage Iâ€™d provision a managed Amazon RDS PostgreSQL database during the same Beanstalk setup, then drop the generated connection string into my environment variables. Finally, Iâ€™d automate the nightly ingest.py run using Elastic Beanstalkâ€™s built-in cron.yaml (or a lightweight AWS Lambda trigger if more flexibility is needed). This stack gives me a fully managed deploymentâ€”API, database, and scheduled ingestionâ€”while letting me focus on code rather than server maintenance.

---
